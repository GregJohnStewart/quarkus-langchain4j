= Hugging Face

include::./includes/attributes.adoc[]

https://huggingface.co/[Hugging Face] is a leading platform in the field of natural language processing (NLP) that provides a comprehensive collection of pre-trained language models. Hugging Face facilitates easy access to a wide range of state-of-the-art models for various NLP tasks.
Its focus on democratizing access to cutting-edge NLP capabilities has made Hugging Face a pivotal player in the advancement of language technology.

== Using Hugging Face models

To employ Hugging Face LLMs, integrate the following dependency into your project:

[source,xml,subs=attributes+]
----
<dependency>
    <groupId>io.quarkiverse.langchain4j</groupId>
    <artifactId>quarkus-langchain4j-hugging-face</artifactId>
    <version>{project-version}</version>
</dependency>
----

If no other LLM extension is installed, link:../ai-services.adoc[AI Services] will automatically utilize the configured Hugging Face model.

IMPORTANT: Hugging Face provides multiple kind of models. We only support **text-to-text** models, which are models that take a text as input and return a text as output.

By default, the extension uses:

- https://huggingface.co/tiiuae/falcon-7b-instruct[titiuas/falcon-7b-instruct] as chat model (inference endpoint: _https://api-inference.huggingface.co/models/tiiuae/falcon-7b-instruct_)
- https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2[sentence-transformers/all-MiniLM-L6-v2] as embedding model (inference endpoint: _https://api-inference.huggingface.co/pipeline/feature-extraction/sentence-transformers/all-MiniLM-L6-v2_)

=== Configuration

Configuring Hugging Face models mandates an API key, obtainable by creating an account on the Hugging Face platform.

The API key can be set in the `application.properties` file:

[source,properties,subs=attributes+]
----
quarkus.langchain4j.huggingface.api-key=hf-...
----

TIP: Alternatively, leverage the `QUARKUS_LANGCHAIN4J_HUGGINGFACE_API_KEY` environment variable.

Several configuration properties are available:

include::includes/quarkus-langchain4j-huggingface.adoc[leveloffset=+1,opts=optional]

== Configuring the chat model

You can change the chat model by setting the `quarkus.langchain4j.huggingface.chat-model.inference-endpoint-url` property.
When using a model hosted on Hugging Face, the property should be set to: `https://api-inference.huggingface.co/models/<model-id>`.

For example, to use the `google/flan-t5-small` model, set:

[source, properties]
----
quarkus.langchain4j.huggingface.chat-model.inference-endpoint-url=https://api-inference.huggingface.co/models/google/flan-t5-small
----

Remember that only text to text models are supported.

== Using inference endpoints and local models

Hugging Face models can be deployed to provide inference endpoints.
In this case, configure the `quarkus.langchain4j.huggingface.inference-endpoint-url` property to point to the endpoint URL:

[source,properties,subs=attributes+]
----
quarkus.langchain4j.huggingface.chat-model.inference-endpoint-url=https://j9dkyuliy170f3ia.us-east-1.aws.endpoints.huggingface.cloud
----

If you run a model locally, adapt the URL accordingly:

[source,properties,subs=attributes+]
----
quarkus.langchain4j.huggingface.chat-model.inference-endpoint-url=http://localhost:8085
----

== Document Retriever and Embedding

When utilizing Hugging Face models, the recommended practice involves leveraging the `EmbeddingModel` provided by Hugging Face.

. If no other LLM extension is installed, retrieve the embedding model as follows:

[source, java]
----
@Inject EmbeddingModel model; // Injects the embedding model
----

You can configure the model using:

[source, properties]
----
quarkus.langchain4j.huggingface.embedding-model.inference-endpoint-url=https://api-inference.huggingface.co/pipeline/feature-extraction/sentence-transformers/all-MiniLM-L6-v2
----

WARNING: Not every sentence transformers are supported by the embedding model. If you want to use a custom sentence transformers, you need to create your own embedding model.

== Tools

The Hugging Face LLMs do not support tools.